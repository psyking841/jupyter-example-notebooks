{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Stocator library to connect to IBMCloud COS for sourcing objects as Spark DataFrame\n",
    "\n",
    "The following examples are using IAM authentication to access objects\n",
    "\n",
    "The Stocator jar used in this demo is built from \n",
    "https://github.com/CODAIT/stocator/tree/1.0.30-ibm-sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Using local Stocator jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming you have downloaded the jar to\n",
    "\"/Users/shengyipan/.m2/repository/com/ibm/stocator/stocator/1.0.30-IBM-SDK/stocator-1.0.30-IBM-SDK.jar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local\")\\\n",
    ".config(\"spark.jars\", \"/Users/shengyipan/.m2/repository/com/ibm/stocator/stocator/1.0.30-IBM-SDK/stocator-1.0.30-IBM-SDK.jar\")\\\n",
    ".config(\"fs.stocator.scheme.list\", \"cos\")\\\n",
    ".config(\"fs.cos.impl\", \"com.ibm.stocator.fs.ObjectStoreFileSystem\")\\\n",
    ".config(\"fs.stocator.cos.impl\", \"com.ibm.stocator.fs.cos.COSAPIClient\")\\\n",
    ".config(\"fs.stocator.cos.scheme\", \"cos\")\\\n",
    ".config(\"fs.cos.myCos.endpoint\", \"https://s3.ams03.objectstorage.softlayer.net\")\\\n",
    ".config(\"fs.cos.myCos.iam.api.key\", \"YOUR_API_KEY\").getOrCreate()\n",
    "#Optional config: .config(\"fs.cos.myCos.iam.service.id\", \"crn:v1:bluemix:public:cloud-object-storage:global:a/xxx:abc::\")\\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=spark.read.csv(\"cos://test-bucket-span001.myCos/source/year=2018/month=08/day=28/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                 _c0|\n",
      "+--------------------+\n",
      "|These examples gi...|\n",
      "|Spark is built on...|\n",
      "|      In the RDD API|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Using remote Stocator jar in JFrog\n",
    "In general the steps are:\n",
    "\n",
    "1. Create settings.xml and put it under $HOME/.ivy2/, or any location if you don't use ivy or you even don't know why ivy is :-)\n",
    "2. Run following python code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1:\n",
    "Create an empty file named \"settings.xml\" then copy and paste following contents into it.\n",
    "Do remember to change the username and passwd to match yours.\n",
    "```\n",
    "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "<ivy-settings>\n",
    "  <settings defaultResolver=\"main\" />\n",
    "  <!--Authentication required for publishing (deployment). 'Artifactory Realm' is the realm used by Artifactory so don't change it.-->\n",
    "  <credentials host=\"na.artifactory.swg-devops.com\" realm=\"Artifactory Realm\" username=\"your-user-name\" passwd=\"your-password\" />\n",
    "  <resolvers>\n",
    "    <chain name=\"main\">\n",
    "      <ibiblio name=\"public\" m2compatible=\"true\" root=\"https://na.artifactory.swg-devops.com:443/artifactory/txo-cedp-garage-artifacts-sbt-local\" />\n",
    "    </chain>\n",
    "  </resolvers>\n",
    "</ivy-settings>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2:\n",
    "from pyspark import SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local\")\\\n",
    ".config(\"spark.jars.ivySettings\", \"/Users/shengyipan/.ivy2/settings.xml\")\\\n",
    ".config(\"spark.jars.packages\", \"com.ibm.stocator:stocator:1.0.30-IBM-SDK\")\\\n",
    ".config(\"fs.stocator.scheme.list\", \"cos\")\\\n",
    ".config(\"fs.cos.impl\", \"com.ibm.stocator.fs.ObjectStoreFileSystem\")\\\n",
    ".config(\"fs.stocator.cos.impl\", \"com.ibm.stocator.fs.cos.COSAPIClient\")\\\n",
    ".config(\"fs.stocator.cos.scheme\", \"cos\")\\\n",
    ".config(\"fs.cos.myCos.endpoint\", \"https://s3.ams03.objectstorage.softlayer.net\")\\\n",
    ".config(\"fs.cos.myCos.iam.api.key\", \"\").getOrCreate()\n",
    "# .config(\"fs.cos.myCos.iam.service.id\", \"crn:v1:bluemix:public:cloud-object-storage:global:a/abc:xyz::\")\\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=spark.read.csv(\"cos://test-bucket.myCos/source/year=2018/month=08/day=28/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                 _c0|\n",
      "+--------------------+\n",
      "|These examples gi...|\n",
      "|Spark is built on...|\n",
      "|      In the RDD API|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Using ibmos2spark package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ibmos2spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOTE THAT you NEED a service id here\n",
    "credentials = {\n",
    "    'endpoint': 'https://s3.ams03.objectstorage.softlayer.net',\n",
    "    'api_key': 'YOUR API KEY',\n",
    "    'service_id': 'crn:v1:bluemix:public:cloud-object-storage:global:a/xxx:aaa::'\n",
    "}\n",
    "\n",
    "# This can by any random string\n",
    "configuration_name = 'myCOS'\n",
    "cos = ibmos2spark.CloudObjectStorage(sc, credentials,\n",
    "                                        configuration_name=configuration_name,\n",
    "                                        cos_type='bluemix_cos',\n",
    "                                        auth_method='api_key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'test-bucket'\n",
    "object_name = 'source/year=2018/month=08/day=31/test.txt'\n",
    "data_url = cos.url(object_name, bucket_name)\n",
    "data = sc.textFile(data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have SparkSession available and have an instance named \"spark\"\n",
    "# You can do following to get datafrom:\n",
    "spark.read.csv(data_url).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. If you would like to import Stocator for spark-submit command\n",
    "1. Finish step 1 above\n",
    "2. Run the following spark command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark-submit \\\n",
    "--master {{ params.spark_master }} \\\n",
    "--deploy-mode {{ params.spark_deploy_mode }} \\\n",
    "--name {{ params.job_name }} \\\n",
    "--conf spark.jars.ivySettings=spark.jars.ivySettings \\\n",
    "--conf spark.jars.packages=\"com.ibm.stocator:stocator:1.0.30-IBM-SDK,com.ibm.cedpgarage:sample-project:1.7.0-SNAPSHOT\" \\\n",
    "--driver-java-options \\\"-Dcos.apiKey={{ params.api_key }} -Dcos.bucketSource=cos://{{ params.input_bucket }}.{{ params.cos_service_name }}/{{ params.input_path }}{{ execution_date | date_to_path() }} -Dcos.bucketDest=cos://{{ params.output_bucket }}.{{ params.cos_service_name }}/{{ params.output_path }}{{ execution_date | date_to_path() }} -Dcos.endpoint={{ params.endpoint_url }} -Dcos.serviceId={{ params.cos_service_id }}\\\" \\\n",
    "--class {{ params.job_class }} \\\n",
    "/path/to/fake.jar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
